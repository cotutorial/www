# www.cotutorial.com

---

How to reduce code execution time using Python and Pytorch

## Problem

When inferring I use 5 DL at ~25k. images simultaneously.

The script took about 4 hours to run.

The problem is that this is not a batch job that runs overnight...

Various people in the company required it to run "real time" several times a day.

Solution?

The first thing that might come to your mind is to start using some fancy optimizer (e.g. TensorRT).

Although it has to be done sometime...

First you should ask yourself:

- I/O bottlenecks: reading and writing images
- pre-processing and post-processing - can they be parallelized?
- are CUDA cores used to their maximum potential?
- is the bandwidth between CPU and GPU limited?
- can we move more calculations to the GPU?

Optimization


1. interface samples were grouped

Batch batching is not only useful for training, but also significantly speeds up inference time.

Otherwise you will waste CUDA GPU cores.

Instead of going through models one sample at a time, I now process 64.


2. Pytorch data loader used

This has 2 main advantages:

- parallel loading and preprocessing of data across multiple processes (NOT threads)
- copying input images directly to pinned memory (avoid CPU -> CPU copy operations)


3. Moved most of the post-processing to the GPU

I saw that the tensor was moved too early on the CPU and mapped to the NumPy array.

I refactored the code to keep it on the GPU as much as possible, which had 2 main advantages:

- tensors are processed faster on GPU
- at the end of the logic I had smaller tensors, which resulted in smaller transfers between CPU and GPU


4. Multi-threading for all my write IO operations

When dealing with I/O bottlenecks, using Python threads is extremely efficient.

I moved all my writes to ð˜›ð˜©ð˜³ð˜¦ð˜¢ð˜¥ð˜—ð˜°ð˜°ð˜­ð˜Œð˜¹ð˜¦ð˜¤ð˜¶ð˜µð˜°ð˜³, grouping my writes.


Please note that I only used good old Python and PyTorch code.

When your code is poorly written, no tool will save you

Only now is the time to add fancy tools like TensorRT.


To optimize your PyTorch code by 82%:

1. Inference samples were grouped
2. The DataLoader module from PyTorch was used
3. Moved most of the post-processing to the GPU
4. Multi-threading for all my write I/O operations


---


## Problem

Podczas wnioskowania uÅ¼ywam 5 DL przy ~ 25 tys. obrazÃ³w jednoczeÅ›nie.

Uruchomienie skryptu zajÄ™Å‚o okoÅ‚o 4 godzin.

Problem w tym, Å¼e nie jest to zadanie wsadowe uruchamiane przez caÅ‚Ä… noc...

RÃ³Å¼ni ludzie w firmie wymagali, aby dziaÅ‚aÅ‚ on â€žw czasie rzeczywistymâ€ kilka razy dziennie.

Rozwiazanie?

PierwszÄ… rzeczÄ…, ktÃ³ra moÅ¼e przyjÅ›Ä‡ Ci do gÅ‚owy, jest rozpoczÄ™cie korzystania z jakiegoÅ› wymyÅ›lnego optymalizatora (np. TensorRT).

ChoÄ‡ kiedyÅ› trzeba to zrobiÄ‡...

Najpierw powinieneÅ› zadaÄ‡ sobie pytanie:

- WÄ…skie gardÅ‚a we/wy: odczytywanie i zapisywanie obrazÃ³w
- przetwarzanie wstÄ™pne i przetwarzanie koÅ„cowe - czy moÅ¼na je zrÃ³wnolegliÄ‡?
- czy rdzenie CUDA sÄ… wykorzystywane z maksymalnym potencjaÅ‚em?
- czy przepustowoÅ›Ä‡ pomiÄ™dzy CPU i GPU jest ograniczona?
- czy moÅ¼emy przenieÅ›Ä‡ wiÄ™cej obliczeÅ„ do GPU?

Optymalizacja


1. pogrupowano prÃ³bki interfejsu

Grupowanie wsadowe jest nie tylko przydatne w szkoleniu, ale takÅ¼e znacznie przyspiesza czas wnioskowania.

W przeciwnym razie zmarnujesz rdzenie GPU CUDA.

Zamiast przeglÄ…daÄ‡ modele po jednej prÃ³bce, przetwarzam teraz 64.


2. Wykorzystywany moduÅ‚ Å‚adujÄ…cy dane Pytorch

Ma to 2 gÅ‚Ã³wne zalety:

- rÃ³wnolegÅ‚e Å‚adowanie i wstÄ™pne przetwarzanie danych w wielu procesach (NIE wÄ…tkach)
- kopiowanie obrazÃ³w wejÅ›ciowych bezpoÅ›rednio do przypiÄ™tej pamiÄ™ci (unikaj operacji kopiowania procesora -> procesora)


3. Przeniesiono wiÄ™kszÄ… czÄ™Å›Ä‡ przetwarzania koÅ„cowego na GPU

WidziaÅ‚em, Å¼e tensor zostaÅ‚ przeniesiony zbyt wczeÅ›nie na procesorze i zmapowany na tablicÄ™ NumPy.

DokonaÅ‚em refaktoryzacji kodu, aby jak najwiÄ™cej trzymaÄ‡ go na GPU, co miaÅ‚o 2 gÅ‚Ã³wne zalety:

- tensory sÄ… przetwarzane szybciej na GPU
- na koniec logiki miaÅ‚em mniejsze tensory, co skutkowaÅ‚o mniejszymi transferami miÄ™dzy CPU i GPU


4. WielowÄ…tkowoÅ›Ä‡ dla wszystkich moich operacji zapisu IO

W przypadku wÄ…skich gardeÅ‚ we/wy uÅ¼ycie wÄ…tkÃ³w Pythona jest niezwykle wydajne.

PrzeniosÅ‚em wszystkie moje zapisy do ð˜›ð˜©ð˜³ð˜¦ð˜¢ð˜¥ð˜—ð˜°ð˜°ð˜­ð˜Œð˜¹ð˜¦ð˜¤ð˜¶ð˜µð˜°ð˜³, grupujÄ…c moje operacje zapisu.

.

PamiÄ™taj, Å¼e uÅ¼yÅ‚em tylko starego, dobrego kodu Python i PyTorch.

Gdy kod jest Åºle napisany, Å¼adne narzÄ™dzie CiÄ™ nie uratuje

Dopiero teraz nadszedÅ‚ czas na dodanie wymyÅ›lnych narzÄ™dzi, takich jak TensorRT.


WiÄ™c pamiÄ™taj...

Aby zoptymalizowaÄ‡ kod PyTorch o 82%:

1. Pogrupowano prÃ³bki wnioskowania
2. Wykorzystano moduÅ‚ DataLoader firmy PyTorch
3. Przeniesiono wiÄ™kszoÅ›Ä‡ postprocessingu na GPU
4. WielowÄ…tkowoÅ›Ä‡ dla wszystkich moich operacji zapisu we/wy


----





[Learn Python with PyCharm for Education](https://www.jetbrains.com/pycharm-edu/)

> # Learn Python  
> in your IDE  
> 
> Perfect your existing skills
> 
> Create educational courses
> 
> Solve coding challenges
> 
> [Download free](https://www.jetbrains.com/education/download/#section=pycharm-edu)
> 
> Whether you are just starting with Python or you are ready to share your programming knowledge with others, you can do it right in the IDE.
> 
> Install PyCharm, go to the _Learn_ tab, and click _Enable Access_. Thatâ€™s it! You can now enjoy learning or teaching Python.
> 
> ![](https://www.jetbrains.com/pycharm-edu/img/pycharm-education.gif)
> 
> Study Python in a way you like! No matter whether you choose to follow a step-by-step course, build an application, or participate in a contest, youâ€™ll learn Python while gaining experience with the IDE, which is a must for a career as a developer.
> 
> ### Interactive courses
> 
> Choose courses based on your proficiency level and learn the basics of Python, or improve your skills in specific subjects like NumPy or Tkinter.
> 
> ### Practice first
> 
> There is no way to learn programming without practice. In our courses, theory is followed by coding exercises to ensure that the concepts really stick.
> 
> ### Instant feedback
> 
> Receive instant feedback on your assignments and get extra assistance with hints and helpful error messages whenever you feel like you are stuck on a task.
> 
> ### Real-world applications
> 
> With the JetBrains Academy integration, you can learn Python by creating applications, such as your own spam filter, chat bot, and a simple search engine.
> 
> ### Programming contests
> 
> If you have experience in Python, challenge yourself with a Codeforces contest. Leverage PyCharmâ€™s features to save some time and get ahead of the competition.
> 
> ### Gamified challenges
> 
> Our CheckiO integration provides gamified coding challenges that you can solve right in your IDEs. Select your proficiency level, start the game, and have fun!




---

+ [edit](https://github.com/cotutorial-com/www/edit/main/README.md)
